{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Measurements_text-generation-using-an-lstm-in-keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afoteygh/Research/blob/main/Measurements_text_generation_using_an_lstm_in_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "cb992059cbdce9902dd23be8246fc180e6c96aa6",
        "id": "-sf-TL7qYkOE"
      },
      "source": [
        "# Text Generation using an LSTM in Keras\n",
        "In this kernel you we will go over how to let a network create text in the style of sir arthur conan doyle. This kernel is heavily based on the [official keras text generation example](https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py).  I also made [a video](https://youtu.be/QtQt1CUEE3w) on text generation using an LSTM network.\n",
        "Content:\n",
        "1. [Introduction](#1)\n",
        "2. [Loading in data](#2)\n",
        "3. [Preprocessing](#3)  \n",
        "    3.1 [Map chars to integers](#3.1)  \n",
        "    3.2 [Split up into subsequences](#3.2)\n",
        "4. [Building model](#4)  \n",
        "    4.1 [Helper Functions](#4.1)  \n",
        "    4.2 [Defining callbacks and training the model](#4.2)\n",
        "5. [Generate new text](#5)  \n",
        "6. [Conclusion](#6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2066f1978370082a41b410a67e440e7ed4cb72c7",
        "id": "cneQdlP0YkOE"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "027dbe6d5cefff7d3eac6147ef54a023dcf36d7d",
        "id": "BBg2HIbaYkOF"
      },
      "source": [
        "<a id=\"1\"></a> \n",
        "## 1. Introduction\n",
        "Because the sequence in an text is important we will recurrent neural network which can remember its previous inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "H6Sq_X1FYkOF"
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "id": "JMSCs4d0YkOG"
      },
      "source": [
        "<a id=\"2\"></a> \n",
        "## 2. Loading in data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e0f294d2dcfa87c33bd3c0906379f44986d1b8d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBhO4a-xYkOG",
        "outputId": "670a89a0-fbf1-4316-e935-4b910109bc96"
      },
      "source": [
        "text = open('LSTMemerging-trojan.txt', 'r').read().lower()\n",
        "print('text length', len(text))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text length 4472199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ee0e4330b29978330549ec6c7014e5a0c9496d06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0TbmPl5YkOG",
        "outputId": "607e152c-3d37-4057-d331-52368fdfaefd"
      },
      "source": [
        "print(text[:400])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "alert tcp $home_net any -> $external_net 25 (msg:\"et trojan suspicious smtp handshake outbound\"; flow:established,to_server; content:\"001 ruthere\"; depth:11; metadata: former_category malware; reference:url,doc.emergingthreats.net/bin/view/main/2008562; classtype:unknown; sid:2008562; rev:3; metadata:created_at 2010_07_30, updated_at 2010_07_30;)\n",
            "\n",
            "alert tcp $external_net 25 -> $home_net any (msg:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "144150bd91525a6a2f026162efec60d443008dae",
        "id": "bwbb-oGkYkOH"
      },
      "source": [
        "<a id=\"3\"></a> \n",
        "## 3. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b40a7e3f910b134f8dbce978e13d01d42088b667",
        "id": "vrq1n-2IYkOH"
      },
      "source": [
        "<a id=\"3.1\"></a> \n",
        "### 3.1 Map chars to integers\n",
        "\n",
        "Because we will be training on a character level we need to relate each unique character with a number.\n",
        "We are going to create two dicts one from character to integer and one to transform back to character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2f424b2f58c7039f62b564a1aeceb5b3c5d86901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2apg9KTYkOH",
        "outputId": "f1971e6b-0f9b-40ac-9842-4d543fd03836"
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars: ', len(chars))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars:  69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "402f6e5ce9e8f7cdc2e7dcb55266aad1a8e3bb09",
        "id": "8xYx1MdPYkOH"
      },
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a7a3ab9e3f6ad6e22a53090e50f4d6d5afdc3283",
        "id": "wqIU1U7FYkOH"
      },
      "source": [
        "<a id=\"3.2\"></a> \n",
        "### 3.2 Split up into subsequences\n",
        "Creates an array of sentence data with the length maxlen as well as an array with the next character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1fb13b2a1bd1ea7f801e751c1327ae59efc85a46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqUIh1wjYkOH",
        "outputId": "e3ffd035-0539-422a-d288-5eb0aa869cff"
      },
      "source": [
        "maxlen = 200\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 1490667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1e627d19acc63ef301ca201de88147afac2990f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV-Pw_1iYkOH",
        "outputId": "0693d6a1-4bfb-44fa-d581-2a8541478c90"
      },
      "source": [
        "print(sentences[:3])\n",
        "print(next_chars[:3])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\nalert tcp $home_net any -> $external_net 25 (msg:\"et trojan suspicious smtp handshake outbound\"; flow:established,to_server; content:\"001 ruthere\"; depth:11; metadata: former_category malware; refere', 'ert tcp $home_net any -> $external_net 25 (msg:\"et trojan suspicious smtp handshake outbound\"; flow:established,to_server; content:\"001 ruthere\"; depth:11; metadata: former_category malware; reference', ' tcp $home_net any -> $external_net 25 (msg:\"et trojan suspicious smtp handshake outbound\"; flow:established,to_server; content:\"001 ruthere\"; depth:11; metadata: former_category malware; reference:ur']\n",
            "['n', ':', 'l']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8def15c914a431fe23459e7aa456d9c480b0ec99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp4Nmtk1YkOI",
        "outputId": "0f48564e-4f96-4bea-c2b9-d78c2d5889d7"
      },
      "source": [
        "# Print length\n",
        "print(len(sentences))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1490667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ef6c437ef7a96590ddaa03b28a0d777f9a069e8b",
        "id": "bWn9O05jYkOI"
      },
      "source": [
        "We need to reshape our data in a format we can pass to the Keras LSTM The shape look like [samples, time steps, features]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a730301d1db3f0f64faa5d6461ed6b8baefe72de",
        "id": "5em8KMsWYkOI"
      },
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "cef36cdb2cd80069386cb0b86573da6b575591f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXX3h3gxYkOI",
        "outputId": "48321a09-f81b-4ec7-b583-cdbece263922"
      },
      "source": [
        "print(x[:3])\n",
        "print(y[:3])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ True False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False  True False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]]\n",
            "[[False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False  True False False False False False False False\n",
            "  False False False False False False False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False  True False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False  True False False False False False False False False False\n",
            "  False False False False False False False False False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0f18f120974528b74cae18b26a2ebff16a9f14a6",
        "id": "tWKLx_BVYkOI"
      },
      "source": [
        "<a id=\"4\"></a> \n",
        "## 4. Building model\n",
        "For this kernel I will use a really small LSTM network but if you want to get better results feel free to replace it with a bigger network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "08cc043586d3804558e0dde91563ac01c58f6a72",
        "id": "GxIZaxuiYkOI"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ca6506184b319333e23a9531f69b956c6e8528bc",
        "id": "bQhIJb1lYkOJ"
      },
      "source": [
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy','mae','mse'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5e3029c587f24cd5eb7a20645e907c2b5815ff77",
        "id": "vtJDZCMvYkOJ"
      },
      "source": [
        "<a id=\"4.1\"></a> \n",
        "### 4.1 Helper Functions\n",
        "\n",
        "I got this function from the lstm_text_generation example from keras. [https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py](https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ddbf609aff0de89026f9367ab02c20fc5055c0cd",
        "id": "3dLTokcWYkOJ"
      },
      "source": [
        "Samples an index from a probability array with some temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "10de369a6283954c1f5564d2f3d152cdf9f9efe2",
        "id": "qLsTz_7nYkOJ"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e59c92fa7e68491270814a2bd209ece712df4672",
        "id": "uK6PUuSoYkOJ"
      },
      "source": [
        "Callback function to print predicted text generated by our LSTM. It prints generated text with 5 different temperatures [0.2, 0.5, 1.0, 1.2]. 0.2 will generate text with more ordinary word. 1.2 will generate wilder guesses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "993684b063bddea5f291c5e710c852da815e3362",
        "id": "sJuL83KMYkOJ"
      },
      "source": [
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "31701fe51d0d0d7dea6bc8c50b5e135c96ecfa75",
        "id": "cekt8llDYkOJ"
      },
      "source": [
        "<a id=\"4.2\"></a> \n",
        "### 4.2 Defining callbacks and training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ded5a7907c6f5d1b7b7fa4e5c8c6cc445bd4a450",
        "id": "wukkdGQ0YkOJ"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = \"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
        "                             verbose=1, save_best_only=True,\n",
        "                             mode='min')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "57f9ab71278ec6584dc3f2a4166b292d3d79163d",
        "id": "KBh0nt0VYkOJ"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=1, min_lr=0.001)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "87f151c81b294538020863d07466c9bebee2c1ea",
        "id": "2gP7Z2TzYkOJ"
      },
      "source": [
        "callbacks = [print_callback, checkpoint, reduce_lr]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a0898aff47687be0d20c30bc8ba35ada5a6cc446",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beBsAULPYkOJ",
        "outputId": "8a01189e-dffb-426e-da01-cf0991171392"
      },
      "source": [
        "model.fit(x, y, batch_size=256, epochs=1, callbacks=callbacks)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5821/5823 [============================>.] - ETA: 0s - loss: 0.8294 - accuracy: 0.7746 - mae: 0.0083 - mse: 0.0041\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"classtype:trojan-activity; sid:2023665; rev:3; metadata:affected_product windows_xp_vista_7_8_10_server_32_64_bit, affected_product mac_osx, attack_target client_endpoint, deployment perimeter, signat\"\n",
            "classtype:trojan-activity; sid:2023665; rev:3; metadata:affected_product windows_xp_vista_7_8_10_server_32_64_bit, affected_product mac_osx, attack_target client_endpoint, deployment perimeter, signature_severity major, created_at 2016_07_01, malware_family abusert, updated_at 2019_09_28;)\n",
            "\n",
            "alert udp $home_net any -> any 53 (msg:\"et trojan abuse.ch ssl blacklist malicious ssl cert (minion cnc checkin\"; flow:established,to_server; content:\".php?maid=\"; http_uri; content:\"&counat=\"; http_uri; content:\"&user-agent|3a 20|mozilla|0d 0a|\"; http_header; content:\"post\"; nocase; http_uri; content:\"&per\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"classtype:trojan-activity; sid:2023665; rev:3; metadata:affected_product windows_xp_vista_7_8_10_server_32_64_bit, affected_product mac_osx, attack_target client_endpoint, deployment perimeter, signat\"\n",
            "classtype:trojan-activity; sid:2023665; rev:3; metadata:affected_product windows_xp_vista_7_8_10_server_32_64_bit, affected_product mac_osx, attack_target client_endpoint, deployment perimeter, signature_severity major, created_at 2011_06_22, malware_family pelat, performance_impact low, updated_at 2016_08_03;)\n",
            "\n",
            "alert tcp $home_net any -> $external_net $http_ports (msg:\"et trojan sslbloader domain postenc malware possible possible microsoft cnc command stcher cnc checkin matich tcreater cnc command)\"; content:\"|01|\"; offset:2; depth:1; content:\"|00 01 00 00 00 00 00|\"; distance:1; within:7; co\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"classtype:trojan-activity; sid:2023665; rev:3; metadata:affected_product windows_xp_vista_7_8_10_server_32_64_bit, affected_product mac_osx, attack_target client_endpoint, deployment perimeter, signat\"\n",
            "classtype:trojan-activity; sid:2023665; rev:3; metadata:affected_product windows_xp_vista_7_8_10_server_32_64_bit, affected_product mac_osx, attack_target client_endpoint, deployment perimeter, signature_severity major, created_at 2016_10_20, malware_family poss axusvat.in)\"; sid:2016285; rev:2; metadata:affected_product linux,)dateated; sid:2027857; rev:3; metadata:created_at 2011_02_01, updated_at 2010_10_22;)\n",
            "\n",
            "alert tcp $home_net any -> $external_net 64 whomload6 1, signature_severity major, created_at 2014_08_15, performance_impact low, updated_at 2019_10_07;)\n",
            "\n",
            "alert udp $home_net any -> a\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"classtype:trojan-activity; sid:2023665; rev:3; metadata:affected_product windows_xp_vista_7_8_10_server_32_64_bit, affected_product mac_osx, attack_target client_endpoint, deployment perimeter, signat\"\n",
            "classtype:trojan-activity; sid:2023665; rev:3; metadata:affected_product windows_xp_vista_7_8_10_server_32_64_bit, affected_product mac_osx, attack_target client_endpoint, deployment perimeter, signature_severity pestro_server, created_at 2011_05_33, updated_at 2019_09_28;)\n",
            "\n",
            "alert udp $home_net any -> any 53 (msg:\"et trojan zeckon.v cheac ransomware c uted/10\"; content:\"|0d|omlaw6.cb)\"; nocase; nocase;\"; pcreated_at 2020_12_06, verver_32_64_it, ertadibtanconc, deployment perimeter, tag eser.htma b0datad user-agereassl[tbata-adubk\"; fast_pattern; content:\"pis\"; http_uri; distance:0; content:!\"o\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.82929, saving model to weights.hdf5\n",
            "5823/5823 [==============================] - 176s 30ms/step - loss: 0.8293 - accuracy: 0.7746 - mae: 0.0083 - mse: 0.0041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe5c0393668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py6sE8gMYkOK",
        "outputId": "5f653a1a-adf4-43d0-b41e-5a81e9999eec"
      },
      "source": [
        "testScore = model.evaluate(x,y, verbose=0)\n",
        "print ('\\nTest Scores:  acc={}, mae={}, mse={}'.format(*testScore)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test Scores:  acc=2.0600175274515076, mae=0.4020946325097816, mse=0.033119961810506984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "72d813d0114724321428166ffc4b40f2cbb3a809",
        "id": "vM37LK7QYkOK"
      },
      "source": [
        "<a id=\"5\"></a> \n",
        "## 5. Generate new text\n",
        "\n",
        "\n",
        "We can generate text using the same approach as in the on_epoch_end helper function create by Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9d2f2eb1e7fec259e85a982e1cff85a9ee8603e2",
        "id": "Msdg1rRwYkOK"
      },
      "source": [
        "def generate_text(length, diversity):\n",
        "    # Get random starting text\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "              \n",
        "    return generated\n",
        "\n",
        "#testScore = model.evaluate(preds, diversity, verbose=0)\n",
        "#print ('\\nTest Scores:  mse={}, mae={}'.format(*testScore))\n",
        "#testScore = model.evaluate(preds, verbose=0)\n",
        "#print ('\\nTest Scores:  acc={}'.format(*testScore)) \n",
        "#print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b295df279033867aa825ca903e96744b2fd10d8c",
        "id": "yNUAlZHRYkOK",
        "outputId": "994dcecf-8b94-4f4e-f71f-d2487905cd57"
      },
      "source": [
        "print(generate_text(5000, 0.2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lf, and shouted out, 'you'd better not dout she mout mout so the much the wat in and the mont the whe the mout the mot so mout the mout it she wat in the mong the mome the she won she wore the the mous so the the what the whe wond and the more the the she pore the whe the she the mout the the mout the what the the the the hame the her the the whe the mone the mont the the coust the mome the the mome the the the were the the moust the moust it and the moust the could the moust whe wor her the she the moust the the the mome the mout the mout wor the whe the whe the more she the the the the wher the she the mont the she the the mong she the was the the she she the ware the sout the she the whe she the whe she the sher the the the she the mout the whe the more the the mout the the the the more the mouse the she mout the mome the wore the the the mont the what the mont she she she wat so the she the the the the mong the she the mout the the the couse the she mong the she the the more the mutt in and the the more the cout to she the has she the mouthe the mout the murt the wond the the mome the mong the the mome the and the she sous the the the was the whe her and the she mong the she mome the the mont the cout so she the she hame she the mome the she the wore the wat so the the mont so the mous the the whe the mome the mout to the coume the the the mor the she the wome the she won the sout in the mout the the more the the she mot the mome the the the must the and the mout she she she the what the she whe the monce the she she she the mome the the mong the whe the the the mout the the mome the the she she whe she moust and all the she she the mutt on the the was she mout the mong the whe her the the mout the whe the mame the she what the mout in the the more the mome the the the for the mout the mert the the mome the the mome the the mome the the more the the she the morse the mont the mout in the the mouthe the has sous the the mound the the mont she whe her and the mort of whe the what so she she the the cous the mome the more the the she the wonke the the mome the she the mong the wont the she she the coust the mout the mont and the mutt of the was in the she wat in the she the the murt the mout the mout to the she the mont she whe the more the was she mathe she the monge the she was she she whe she the the mout the she mome the the had the whe was in what and the she won the mout sous the the was it the mome the whe the monge the mout so the mout the mome the mont the more the what and the the the the mome the the mong the the the the whe the coute the she the mert the murt the whe she wont the mout in and the more the the her the whe she whe she whe the she the she mout in the the mous the wont to moust the cout the whe the the the she the the whe wous she wand the the cout so the the more the whing the she the mout whe the butt of the the mome the she the the the matt the the mont she she wong the she mout so the the mome the she the murt the the the mond the the whe the mome the mad the the whe the mort the whe her the the the she the she the she the mong the she she the cher the mout in and the the mont the the she more the wand the was in and and the she the cous the she the whe the mast the she the the the the the whot the the mome the the whe the mout in and the moutt it and the the mout so the the mout so she the whe she the mous the the coutt the the wand the whe the mome the she the mome the she she mout to the she wore the whe the mont in and the mout she the want the the mome the mont so the whe she mome the mont the more she whe she wher she the more the what to the monge the coust and the whe soust the the mome she the the murte the she she she the mout to the whe the must the she mout in the she the whe the mont and the the wat in the what in and the the muthe the she mont the mong the the was the cound the more the coust it she the whe the mome the was the and the she the the mort the cout in the the she the more the much mo the the and and the the coust and the mon the she the wat and the mor the she mous she what in and the she whe the mutt the was sous the what and the whe she the more the coust and the mont the cout so the muct and the mout so she the mot the cound the the mout and the moust the mout sous the she was in the whe she couthe the mout to the the she was the mome she whon the mout the the mome the mout so the she the whe sout in and the the she whe the mongen all the mor the sout in the what and the the she whe the she the the whe wint the the more the whe she the wand the mome the mome the the the wand the mome the the mont the she was the the she souse the the the mome the wont the mont the whe and the was she whe the mond the the mont the mome the she whe the the murt the she the she cooke the the whe the she the mone the whe the more the more the the the mout sous to she whe the the coutt she the mout the the more the whe sout she whe she the wand the mont she mome the wont the she mout so the the mont and and th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rcC15wnYkOK"
      },
      "source": [
        "#testScore = model.evaluate(preds, diversity, verbose=0)\n",
        "#print ('\\nTest Scores:  mse={}, mae={}'.format(*testScore))\n",
        "\n",
        "# print(\"##############################################################\")\n",
        "# print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))\n",
        "# print(\"Kappa Stats:\",metrics.cohen_kappa_score(y_test, predictions))\n",
        "# print(\"Precision:\",metrics.precision_score(y_test, predictions))\n",
        "# print(\"Recall:\",metrics.recall_score(y_test, predictions))\n",
        "# print(\"Mean Absolute Error:\",metrics.mean_absolute_error(y, preds))\n",
        "# print(\"Mean Squared Error:\",metrics.mean_squared_error(diversity, preds))\n",
        "# print(\"F-Measure:\",metrics.recall_score(y_test, predictions))\n",
        "# print(\"##############################################################\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f93a5fa5593130757a2e36409e0cfee68b53b939",
        "id": "mBQ-3MXDYkOK"
      },
      "source": [
        "<a id=\"6\"></a> \n",
        "## 6. Conclusion\n",
        "\n",
        "\n",
        "After 5 epochs our LSTM performed a ok job and I'm more than satisfied with the result.\n",
        "\n",
        "Here are a few things you can change to get better results\n",
        "\n",
        "1. Add more LSTM Layers.\n",
        "2. Use more LSTM Cells.\n",
        "3. Train for more than 5 epochs. (25+)\n",
        "4. Add dropout Layer.\n",
        "5. Play around with the batch-size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzBjMeDzYkOK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}